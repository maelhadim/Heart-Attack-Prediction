{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10806451,"sourceType":"datasetVersion","datasetId":6707768}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A Data Analysis project that aims to extract insights out of the dataset that is a available on Kaggle \"Heart-Attack-Prediction in the united states\" This project aims to go on a step-by-step data analysis sequence. It starts by the most convenient, practical, and logical process to start with on data science which is, data cleaning. The project goes on five phases of data cleaning, which are. Handling missing values, remove duplicates, fix data types, detect and treate outliers, and check for inconsistencies. The project is to be complete on different stages of analysis (Heart attack risk factors, predicting heart attack probability, demographic disparities, and other more) and as each stage is done and complete, the Notebook will be edited accordingly.\n\n**Finally, please note that this is a data analysis project that is being analyazed by a data analyzer who has no medical experience or knowledge. Thus, this project should not be used for any medical consumption or treat it is only applicable for research-based purposes.**","metadata":{}},{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:15.521676Z","iopub.execute_input":"2025-03-01T11:14:15.522061Z","iopub.status.idle":"2025-03-01T11:14:15.931726Z","shell.execute_reply.started":"2025-03-01T11:14:15.522030Z","shell.execute_reply":"2025-03-01T11:14:15.930365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/heart-attack-prediction-in-united-states/heart_attack_dataset.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:15.933030Z","iopub.execute_input":"2025-03-01T11:14:15.933551Z","iopub.status.idle":"2025-03-01T11:14:18.694852Z","shell.execute_reply.started":"2025-03-01T11:14:15.933518Z","shell.execute_reply":"2025-03-01T11:14:18.693771Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Before staritng the data analysis of this data set \"Heart-attack-prediction. We need to preform some data cleaning process so the data is perfect to be analyzed. Some of the steps we are going to preform on cleaning the dataset involves handling missing values, remove duplicates, fix data types, and some more that we will highlight throughout the process\nNow lets get started","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"#Handling Missing Values\n\ndf.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:18.696592Z","iopub.execute_input":"2025-03-01T11:14:18.696876Z","iopub.status.idle":"2025-03-01T11:14:18.969137Z","shell.execute_reply.started":"2025-03-01T11:14:18.696851Z","shell.execute_reply":"2025-03-01T11:14:18.968253Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Even though, the dataset showing 0-missing values for all columns, there still potential data cleaning needed to ensure perfection. ","metadata":{}},{"cell_type":"code","source":"#Here we will look for any duplicates\n#getting rid of duplicates ensures no distort or bias on the result of the analysis\n\ndf.duplicated().sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:18.970693Z","iopub.execute_input":"2025-03-01T11:14:18.971135Z","iopub.status.idle":"2025-03-01T11:14:19.493096Z","shell.execute_reply.started":"2025-03-01T11:14:18.971086Z","shell.execute_reply":"2025-03-01T11:14:19.492007Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"No dubplicats on the dataset,","metadata":{}},{"cell_type":"code","source":"#Veryfing the data types\ndf.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:19.494393Z","iopub.execute_input":"2025-03-01T11:14:19.494883Z","iopub.status.idle":"2025-03-01T11:14:19.502569Z","shell.execute_reply.started":"2025-03-01T11:14:19.494840Z","shell.execute_reply":"2025-03-01T11:14:19.501581Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"All columns are on the corrct data-type. Yet, some columns(e.g.,Gender, SrtokHistory, PreviousHeartAttack, etc) can still be/get grouped under a 'category' data type. ","metadata":{}},{"cell_type":"code","source":"#We will convert some of the object data type columns in to a category data type columns\n\ncategorics_cols = [\"Gender\", \"Smoker\", \"Diabetes\", \"Hypertension\", \"FamilyHistory\",\n   \"PhysicalActivity\", \"AlcoholConsumption\", \"Diet\", \"StressLevel\", \n   \"Ethnicity\", \"Income\", \"EducationLevel\", \"Medication\", \"ChestPainType\",\n   \"ECGResults\", \"ExerciseInducedAngina\", \"Slope\", \"Thalassemia\", \"PreviousHeartAttack\",\n   \"StrokeHistory\", \"Residence\", \"EmploymentStatus\", \"MaritalStatus\"] #A list of the columns that we want to change its data type to categorical\ndf[categorics_cols] = df[categorics_cols].astype(\"category\")#changing the object data type columns into categorical columns\ndf[categorics_cols].dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:19.503669Z","iopub.execute_input":"2025-03-01T11:14:19.504086Z","iopub.status.idle":"2025-03-01T11:14:19.981738Z","shell.execute_reply.started":"2025-03-01T11:14:19.504042Z","shell.execute_reply":"2025-03-01T11:14:19.980738Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Our object-type columns are now a categorical type.\nthat will help us in many way in our analysis. Such as, dealing with categorical data types is more memory efficient because they store unique valus only once. As well as operations like grouping/filtering are faster. ","metadata":{}},{"cell_type":"code","source":"#Next, we will ensure that all the numerical columns are type int64 or float64\n\nnumerical_cols = [\"Age\", \"Cholesterol\", \"BloodPressure\", \"HeartRate\", \n  \"BMI\", \"MaxHeartRate\", \"ST_Depression\", \"NumberOfMajorVessels\"]\ndf[numerical_cols].dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:19.982977Z","iopub.execute_input":"2025-03-01T11:14:19.983345Z","iopub.status.idle":"2025-03-01T11:14:19.997297Z","shell.execute_reply.started":"2025-03-01T11:14:19.983317Z","shell.execute_reply":"2025-03-01T11:14:19.996038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Now we will ensure that no value is stored as string accidentally\n\nall_numeric = all(df[col].astype(str).str.isnumeric().all() for col in numerical_cols)\nall_numeric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:20.000525Z","iopub.execute_input":"2025-03-01T11:14:20.000882Z","iopub.status.idle":"2025-03-01T11:14:20.863224Z","shell.execute_reply.started":"2025-03-01T11:14:20.000853Z","shell.execute_reply":"2025-03-01T11:14:20.861652Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Getting a False indicates that we at least have one value in \"all_numeric\" that is not pure numeric string.","metadata":{}},{"cell_type":"code","source":"#We will troubleshoot and find the values which are causing the problem\n\nfor col in numerical_cols:\n    if not df[col].astype(str).str.isnumeric().all():#Checkin if the values are numeric\n        print(f\"Column '{col}' has non-numeric values:\", df[col].astype(str)[~df[col].astype(str).str.isnumeric()].unique())\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:20.865445Z","iopub.execute_input":"2025-03-01T11:14:20.865759Z","iopub.status.idle":"2025-03-01T11:14:23.316888Z","shell.execute_reply.started":"2025-03-01T11:14:20.865732Z","shell.execute_reply":"2025-03-01T11:14:23.315635Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The output shows that the two columns BMI and ST_Depression have values which are not numeric.\nstr.isnumeric() only accepts whole numbers without decimal point. However, these values are valid floating-point numbers, not non-numeric data.","metadata":{}},{"cell_type":"code","source":"#converts the columns (BMI and ST_Depression) to float64\n\ndf[\"BMI\"] = pd.to_numeric(df[\"BMI\"], errors='coerce')\ndf[\"ST_Depression\"] = pd.to_numeric(df[\"ST_Depression\"], errors='coerce')\n\ndf[\"BMI\"].dtypes, df[\"ST_Depression\"].dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:23.318260Z","iopub.execute_input":"2025-03-01T11:14:23.318607Z","iopub.status.idle":"2025-03-01T11:14:23.328171Z","shell.execute_reply.started":"2025-03-01T11:14:23.318562Z","shell.execute_reply":"2025-03-01T11:14:23.327086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Handele NaN Values\ndf[\"BMI\"] = df[\"BMI\"].fillna(df[\"BMI\"].mean()).infer_objects(copy=False)\ndf[\"ST_Depression\"] = df[\"ST_Depression\"].fillna(df[\"ST_Depression\"].mean()).infer_objects(copy=False)\n\nlen(df[\"BMI\"].isna()), len(df[\"ST_Depression\"].isna())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:23.329579Z","iopub.execute_input":"2025-03-01T11:14:23.330026Z","iopub.status.idle":"2025-03-01T11:14:23.473404Z","shell.execute_reply.started":"2025-03-01T11:14:23.329985Z","shell.execute_reply":"2025-03-01T11:14:23.472230Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"this indicats that our two columns BMI and ST_Depression has no missing values","metadata":{}},{"cell_type":"markdown","source":"Next step after Fix Data Types, is to Detect and Treat Outliers.\nOutliers are extrem values (e.g., Age=150). the IQR (InterQuartile Range) is a statical method to identify them. \nWe will preform the IQR on all the numerical data type columns.","metadata":{}},{"cell_type":"code","source":"#Calculating IQR for numerical type columns\n#We will define a column that caluculate the IQR for us\n\ndef calculate_iqr_bounds(df, columns):\n     results = {}\n     for col in columns:\n        Q1 = df[col].quantile(0.25)\n        Q3 = df[col].quantile(0.75)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        results[col] = {\n            f\"{col}: Lower bound = {lower_bound:.2f}. Values below this may be outliers.\",\n            f\"{col}: Upper bound = {upper_bound:.2f}. Values above this may be outliers.\"\n        }\n     return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:23.474736Z","iopub.execute_input":"2025-03-01T11:14:23.475226Z","iopub.status.idle":"2025-03-01T11:14:23.481516Z","shell.execute_reply.started":"2025-03-01T11:14:23.475182Z","shell.execute_reply":"2025-03-01T11:14:23.480216Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This is a function that will not only help us calculating the IQR, but it will also print out the upper and lower ranges for the column.\nNext we will us the function with all the numerical columns. Then, we will treat Outliers","metadata":{}},{"cell_type":"code","source":"calculate_iqr_bounds(df, \n['Age',\n 'Cholesterol',\n 'BloodPressure',\n 'HeartRate',\n 'BMI',\n 'MaxHeartRate',\n 'ST_Depression',\n 'NumberOfMajorVessels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:23.482729Z","iopub.execute_input":"2025-03-01T11:14:23.483181Z","iopub.status.idle":"2025-03-01T11:14:23.616512Z","shell.execute_reply.started":"2025-03-01T11:14:23.483118Z","shell.execute_reply":"2025-03-01T11:14:23.615470Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Using the function we created (the \"calculate_iqr_bounds(df, columns)\" function) we managed to find the upper and lower bounds for each numerical column","metadata":{}},{"cell_type":"markdown","source":"The next step is to Treat the Outliers. And when preforming this step you get to choose between three options\n1. Cap Values: Replacing outliers with bound values\n2. Remove: Droping the outlier rows\n3. Keep: if outliers are valid\nBased on our dataset we will choose to Cap Values","metadata":{}},{"cell_type":"markdown","source":"There is one important operation needs to be done before actually treating outliers. That is to determin whether outliers are errors or valid data. To do that we will preform a statistical investigation that is, we will use distribution visualization to. particularly we will use boxplot which will help us to display median, quartiles, and any points that fall outside the typical rang. ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Plotting a boxplot\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(12,6))\n\nsns.boxplot(data=df[numerical_cols])\nplt.xticks(rotation=45)\nplt.title(\"Boxplot of Numerical Features\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:23.617666Z","iopub.execute_input":"2025-03-01T11:14:23.618048Z","iopub.status.idle":"2025-03-01T11:14:25.271338Z","shell.execute_reply.started":"2025-03-01T11:14:23.618018Z","shell.execute_reply":"2025-03-01T11:14:25.270258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plotting ST_Depression and NumberOfMajorVessels for better readablity\nsns.boxplot(data=df[[\"ST_Depression\", \"NumberOfMajorVessels\"]])\nplt.xticks(rotation=45)\nplt.title(\"ST_Depression and NumberOfMajorVessels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:25.272303Z","iopub.execute_input":"2025-03-01T11:14:25.272923Z","iopub.status.idle":"2025-03-01T11:14:25.542373Z","shell.execute_reply.started":"2025-03-01T11:14:25.272891Z","shell.execute_reply":"2025-03-01T11:14:25.541234Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"These tow visualizations indecates that no extreme outliers are present for our numerical datasets. Thus, we can move to the next step.","metadata":{}},{"cell_type":"markdown","source":"Resolve Inconsistencies: typos, mismatched categories, or contradicoty data(e.g., age = 5, smoker=yes) which reduces the quality of the data","metadata":{}},{"cell_type":"code","source":"df[categorics_cols].dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:25.543613Z","iopub.execute_input":"2025-03-01T11:14:25.543978Z","iopub.status.idle":"2025-03-01T11:14:25.555372Z","shell.execute_reply.started":"2025-03-01T11:14:25.543947Z","shell.execute_reply":"2025-03-01T11:14:25.554462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"Gender\"].value_counts()#Spotting issues(e.g., Meal instade of Male)\n\n#Incase of a typos\ndf[\"Gender\"].replace({'Meal': 'Male'})\n\ndf[(df[\"Smoker\"] == \"yes\") & (df[\"Age\"] < 10)]#This checks if a smoker is actually under the age of 10. In that case we would either correct or drop these values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:25.556522Z","iopub.execute_input":"2025-03-01T11:14:25.556882Z","iopub.status.idle":"2025-03-01T11:14:25.591362Z","shell.execute_reply.started":"2025-03-01T11:14:25.556842Z","shell.execute_reply":"2025-03-01T11:14:25.590274Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"These operations are done repeatedly on all the categorical columns\nFortunately our dataset has no any Inconsistency that would need to be resolved.  ","metadata":{}},{"cell_type":"markdown","source":"At this stage, we can happily say that our data set has been cleand and fully ready to be analyzed and extract insights out of it to the best levels.\nHere is a recap of what we have done in this process of cleaning our dataset\n1. Handle Missing Values\n2. Remove duplicates (no in our case)\n3. Fix data types\n4. Detect and treate outliers (only detected them we have not had to treat them\n5. Check for Inconsistencies","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"After, data cleaning we move to the second essential data analysis step which is Exploratory Data Analysis (EDA).\nIn this step we will go through different phases which are:\n1. Understand dataset structure\n2. Visualize data Distributions\n3. Identify relationships and correlations\n4. Analyze target variable\n5. Check data quality and pattrens\n6. Documents and summerize findings\n","metadata":{}},{"cell_type":"markdown","source":"Before actually jumping into EDA. We need to highlight some important domain knowledge. Having domain knowledge will help in interpreting the dataset's variables, validating our findings and will ensure our analysis aligns with medical realities.","metadata":{}},{"cell_type":"markdown","source":"*Heart-Attack*\noccures to an individual when flow of blood to the heart is severely reduced or even blocked.\nsource: [Heart-attack](http://www.mayoclinic.org/diseases-conditions/heart-attack/symptoms-causes/syc-20373106)","metadata":{}},{"cell_type":"markdown","source":"**Risk-Factors**\n1. **Gender**:Research shows that along with typical risk factors—such as high blood pressure, high cholesterol, and diabetes—men are at increased risk of heart attack earlier in life due to hormone changes, abdominal obesity, and emotional challenges in middle adulthood. source: [Gender](https://www.medstarhealth.org/blog/heart-disease-men#:~:text=Research%20shows%20that%20along%20with%20typical%20risk%20factors%E2%80%94such,abdominal%20obesity%2C%20and%20emotional%20challenges%20in%20middle%20adulthood.)\n2. **Cholesterol**: HDL(\"good\" Cholesterol) is the one that needs to be high (idealy above 60). LDL(\"bad\" Cholesterol) the one that needs to be low (below 100). Total should be below 200. source: [Ideal Cholesterol Levels](https://my.clevelandclinic.org/health/articles/11920-cholesterol-numbers-what-do-they-mean)\n3. **Blood Pressure**: Blood pressure is considerd high in case of consistent systolic readings of 130 mm Hg or higher, or diastolic readings of 80 mm Hg or higher. source: [Blood Pressure Ranges](https://www.nhlbi.nih.gov/health/high-blood-pressure#:~:text=Your%20blood%20pressure%20is%20high%20when%20you%20have,usually%20occur%20until%20it%20causes%20serious%20health%20problems.)\n4. **Heart Rate**: normal heart rate is between 60 and 100 beats per minute (60-100/min). source:[Heart Rates](https://www.healthdirect.gov.au/resting-heart-rate#:~:text=For%20adults%2C%20a%20normal%20resting%20heart%20rate%20is,neck%20and%20counting%20the%20beats%20for%20one%20minute.)\n5. **BMI(Body Mass Index)**: A BMI between 18.5 and 25kg/m^2 indicates a normal weight. A BMI of less than 18.5kg/m^2 considered underweight. A BMI between 25kg/m^2 and 29.9kg/m^2 is considered overweight. A BMI of 30kg/m^2 or higher is considered obese. source: [BMI Ranges](https://www.heart.org/en/healthy-living/healthy-eating/losing-weight/bmi-in-adults#:~:text=A%20BMI%20between%2018.5%20and%2025%20kg%2Fm%C2%B2%20indicates,of%2030%20kg%2Fm%C2%B2%20or%20higher%20is%20considered%20obese.)\n6. **Smoking**: a major risk factor for hearrt disease. It dameges the blood vassels. source: [Smoking Effects on blood vassels](https://www.nhlbi.nih.gov/health/heart/smoking#:~:text=Smoking%20is%20a%20major%20risk%20factor%20for%20heart,develop%20atherosclerosis%2C%20or%20plaque%20buildup%20in%20the%20arteries.)\n7. **Alcoholic Consumption**:Moderate drinking does not reduce the risk of death. Instead, it may increase the risk of chronic diseases like cancer and heart disease. source: [Alcoholic Consumption](https://www.cdc.gov/alcohol/about-alcohol-use/moderate-alcohol-use.html#:~:text=Moderate%20drinking%20increases%20health%20risks%20compared%20to%20not,cancer%20and%20heart%20disease.%203%204%205%20)\n8. **Physical Activity**: all adults shoud undertake 150-300mins of moderate-intensity, or 75-150mins of vigorous-intensity per week. source:[Physical Activity](https://pmc.ncbi.nlm.nih.gov/articles/PMC7719906/#:~:text=All%20adults%20should%20undertake%20150%E2%80%93300%20min%20of%20moderate-intensity%2C,moderate-intensity%20and%20vigorous-intensity%20aerobic%20physical%20activity%2C%20per%20week.)\n9. **Family History**: family history of cardiovascular disease (CVD) modifies future CVD risk. Siblings of patients with CVD have about 40% risk increase. source: [Family history with CVD](https://pmc.ncbi.nlm.nih.gov/articles/PMC4229162/#:~:text=Family%20history%20of%20CVD%20modifies%20future%20CVD%20risk,CVD%20have%20a%2060%25%20to%2075%25%20risk%20increase.)\n10. **Income and Education Level**: Lower income and education correlate with higher risk due to limited access to healthcare. source:[Low Education and CVD](https://pmc.ncbi.nlm.nih.gov/articles/PMC11017042/)\n11. **Employment and Residence Status**: Prevalences of adverse health outcomes increased with unemployment duration and were highest for those unable to work. Employment is a health equity issue. source: [Employment and Health issues](https://pmc.ncbi.nlm.nih.gov/articles/PMC8678322/)\n12. **Marital Status**: Unmarried patients with known or suspected CAD have an increased risk of all-cause and CVD mortality compared with married ones. source:[Marital Status and CVD](https://www.ahajournals.org/doi/full/10.1161/jaha.117.005890)","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:25.592223Z","iopub.execute_input":"2025-03-01T11:14:25.592470Z","iopub.status.idle":"2025-03-01T11:14:25.744497Z","shell.execute_reply.started":"2025-03-01T11:14:25.592448Z","shell.execute_reply":"2025-03-01T11:14:25.743457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"All the statical measurment we would want to consider in order to understand the distribution of our datasets variables.","metadata":{}},{"cell_type":"markdown","source":"# EDA \n# 1. Understanding Data Structure","metadata":{}},{"cell_type":"markdown","source":"In this section of the EDA, we will try to understand how our data is represented using the essential backbone information of statistics which lies under mean, median, min, max, and quartiles.\nA part form these theoretical statical information, we also believe that a picture is worth a thousand words, and that is why we will use a totally general visualization to see the full picture of the dataset. After that we will dive into more details and extract useful analysis.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:25.745640Z","iopub.execute_input":"2025-03-01T11:14:25.745929Z","iopub.status.idle":"2025-03-01T11:14:25.814348Z","shell.execute_reply.started":"2025-03-01T11:14:25.745904Z","shell.execute_reply":"2025-03-01T11:14:25.813407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:25.815406Z","iopub.execute_input":"2025-03-01T11:14:25.815720Z","iopub.status.idle":"2025-03-01T11:14:25.931215Z","shell.execute_reply.started":"2025-03-01T11:14:25.815686Z","shell.execute_reply":"2025-03-01T11:14:25.930202Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"'Age',\n 'Cholesterol',\n 'BloodPressure',\n 'HeartRate',\n 'BMI',\n 'MaxHeartRate',\n 'ST_Depression',\n 'NumberOfMajorVessels'","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.histplot(data=df, x=\"Age\", hue=\"Outcome\",bins=100, kde=True)\nplt.title(\"Distribution of Age\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.show()\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:15:29.516424Z","iopub.execute_input":"2025-03-01T11:15:29.516906Z","iopub.status.idle":"2025-03-01T11:15:31.897044Z","shell.execute_reply.started":"2025-03-01T11:15:29.516874Z","shell.execute_reply":"2025-03-01T11:15:31.895959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.boxplot(data=df, y='Cholesterol')\nplt.ylabel(\"Cholesterol (mg/dL\")\nplt.title(\"Boxplot of Cholesterol Levels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:28.482475Z","iopub.execute_input":"2025-03-01T11:14:28.482794Z","iopub.status.idle":"2025-03-01T11:14:28.746891Z","shell.execute_reply.started":"2025-03-01T11:14:28.482758Z","shell.execute_reply":"2025-03-01T11:14:28.745711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Comparing cholesterol Levels by gender\nplt.figure(figsize=(8,6))\nsns.boxplot(data=df, x=\"Gender\", y=\"Cholesterol\")\nplt.title(\"Cholesterol Levels By Gender\")\nplt.xlabel(\"Gender\")\nplt.ylabel(\"Cholesterol Level (mg/dL)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:28.751379Z","iopub.execute_input":"2025-03-01T11:14:28.751727Z","iopub.status.idle":"2025-03-01T11:14:29.093895Z","shell.execute_reply.started":"2025-03-01T11:14:28.751697Z","shell.execute_reply":"2025-03-01T11:14:29.092651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(data=df, x=\"Gender\", hue=\"Outcome\", palette=\"deep\")\nplt.title(\"Distribution of Gender in Heart Attack dataset\")\nplt.xlabel(\"Gender\")\nplt.ylabel(\"Count\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:29.095399Z","iopub.execute_input":"2025-03-01T11:14:29.095785Z","iopub.status.idle":"2025-03-01T11:14:29.529773Z","shell.execute_reply.started":"2025-03-01T11:14:29.095756Z","shell.execute_reply":"2025-03-01T11:14:29.528450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"Gender\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:29.531187Z","iopub.execute_input":"2025-03-01T11:14:29.531611Z","iopub.status.idle":"2025-03-01T11:14:29.543001Z","shell.execute_reply.started":"2025-03-01T11:14:29.531567Z","shell.execute_reply":"2025-03-01T11:14:29.541701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\ncorrelation_matrix = df[numerical_cols].corr()\ncorrelation_matrix.fillna(0, inplace=True)  # Replace NaN with 0\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", center=0)\nplt.title(\"Correlation Heatmap For the Numerical Values\")\n\ndf.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf.dropna(inplace=True)\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:29.544294Z","iopub.execute_input":"2025-03-01T11:14:29.544737Z","iopub.status.idle":"2025-03-01T11:14:30.419111Z","shell.execute_reply.started":"2025-03-01T11:14:29.544687Z","shell.execute_reply":"2025-03-01T11:14:30.417862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.violinplot(data=df, x=\"Gender\", y=\"Age\")\nplt.title(\"Age Distribution By Gender\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:30.420220Z","iopub.execute_input":"2025-03-01T11:14:30.420535Z","iopub.status.idle":"2025-03-01T11:14:31.289122Z","shell.execute_reply.started":"2025-03-01T11:14:30.420506Z","shell.execute_reply":"2025-03-01T11:14:31.288006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This output suggests that the number of ages for both Genders varies between 30(lower bound) and 80(upper bound)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:31.290453Z","iopub.execute_input":"2025-03-01T11:14:31.290854Z","iopub.status.idle":"2025-03-01T11:14:31.302214Z","shell.execute_reply.started":"2025-03-01T11:14:31.290809Z","shell.execute_reply":"2025-03-01T11:14:31.301030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Which age has the biggest number of heart attack?\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(18,6))\nsns.kdeplot(data=df, x=\"Age\", hue=\"Outcome\", common_norm=False, fill=True, alpha=0.4)\nplt.title(\"Number of Heart Attack By Age\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:31.303721Z","iopub.execute_input":"2025-03-01T11:14:31.304134Z","iopub.status.idle":"2025-03-01T11:14:33.341755Z","shell.execute_reply.started":"2025-03-01T11:14:31.304093Z","shell.execute_reply":"2025-03-01T11:14:33.340688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_age = df.groupby([\"Age\", \"Outcome\"]).size().reset_index(name=\"Count\")\ndf_age #a count of unique occurrences by age and outcome columns and resets the index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:33.343007Z","iopub.execute_input":"2025-03-01T11:14:33.343410Z","iopub.status.idle":"2025-03-01T11:14:33.393038Z","shell.execute_reply.started":"2025-03-01T11:14:33.343371Z","shell.execute_reply":"2025-03-01T11:14:33.392057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Calculating percentage for each age group \ndf_age[\"Percentage\"] = df_age.groupby(\"Age\")[\"Count\"].apply(lambda x: x / x.sum() * 100).reset_index(drop=True)\ndf_age","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:33.394265Z","iopub.execute_input":"2025-03-01T11:14:33.394749Z","iopub.status.idle":"2025-03-01T11:14:33.426079Z","shell.execute_reply.started":"2025-03-01T11:14:33.394701Z","shell.execute_reply":"2025-03-01T11:14:33.424807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.barplot(\n    data=df_age,\n    x=\"Age\",\n    y=\"Percentage\",\n    hue=\"Outcome\"\n)\nplt.title(\"Percentage of Heart Attacks by Age\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:33.427781Z","iopub.execute_input":"2025-03-01T11:14:33.428209Z","iopub.status.idle":"2025-03-01T11:14:35.140690Z","shell.execute_reply.started":"2025-03-01T11:14:33.428143Z","shell.execute_reply":"2025-03-01T11:14:35.139613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The number of cases appears to be in a uniform distribution across all ages. The number of cases of Heart-Attack and No-Heart-Attack are similler and almost exactly 50% divided","metadata":{}},{"cell_type":"code","source":"df[\"Smoker\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T11:14:35.141529Z","iopub.execute_input":"2025-03-01T11:14:35.141788Z","iopub.status.idle":"2025-03-01T11:14:35.151663Z","shell.execute_reply.started":"2025-03-01T11:14:35.141765Z","shell.execute_reply":"2025-03-01T11:14:35.150675Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n**At this point can confidently say that the dataset is actually AI-Generated dataset. And all credits, and thanks is actually for the powerful process of Exploratory Data Analysis (EDA) that has revealed the unnatural distributions, highly uniform patterns, and unrealistic correlations. these anomalies highlight the importance of data validation before analysis ensure meaningful insights. In case of starting without preforming any EDA, we would go to directly preform feature Selection and Engineering. In which we would identify most relevant features for the analysis which are the gender, Physical Activity, Gender, and some more. But these features are only considered in real-life aspects (our data is AI-Generated so nothing would have seemed to add-up).**","metadata":{}}]}